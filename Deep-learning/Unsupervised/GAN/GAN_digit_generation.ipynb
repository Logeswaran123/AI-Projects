{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-1b9e9c7674f9>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From E:\\Misc\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From E:\\Misc\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../03-Convolutional-Neural-Networks/MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From E:\\Misc\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../03-Convolutional-Neural-Networks/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From E:\\Misc\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ../03-Convolutional-Neural-Networks/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../03-Convolutional-Neural-Networks/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From E:\\Misc\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"../03-Convolutional-Neural-Networks/MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x208ae64a20>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.train.images[5].reshape(28,28),cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Networks\n",
    "\n",
    "Useful Links:\n",
    "\n",
    "https://stackoverflow.com/questions/45307072/using-leaky-relu-in-tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z,reuse=None):\n",
    "    with tf.variable_scope('gen',reuse=reuse):\n",
    "        hidden1 = tf.layers.dense(inputs=z,units=128)\n",
    "        # Leaky Relu\n",
    "        alpha = 0.01\n",
    "        hidden1 = tf.maximum(alpha*hidden1,hidden1)\n",
    "        hidden2 = tf.layers.dense(inputs=hidden1,units=128)\n",
    "        \n",
    "        hidden2 = tf.maximum(alpha*hidden2,hidden2)\n",
    "        output = tf.layers.dense(hidden2,units=784,activation=tf.nn.tanh)\n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(X,reuse=None):\n",
    "    with tf.variable_scope('dis',reuse=reuse):\n",
    "        hidden1 = tf.layers.dense(inputs=X,units=128)\n",
    "        # Leaky Relu\n",
    "        alpha = 0.01\n",
    "        hidden1 = tf.maximum(alpha*hidden1,hidden1)\n",
    "        \n",
    "        hidden2 = tf.layers.dense(inputs=hidden1,units=128)\n",
    "        hidden2 = tf.maximum(alpha*hidden2,hidden2)\n",
    "        \n",
    "        logits = tf.layers.dense(hidden2,units=1)\n",
    "        output = tf.sigmoid(logits)\n",
    "    \n",
    "        return output, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images = tf.placeholder(tf.float32,shape=[None,784])\n",
    "z = tf.placeholder(tf.float32,shape=[None,100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = generator(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_output_real , D_logits_real = discriminator(real_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_output_fake, D_logits_fake = discriminator(G,reuse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(logits_in,labels_in):\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits_in,labels=labels_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_real_loss = loss_func(D_logits_real,tf.ones_like(D_logits_real)* (0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_fake_loss = loss_func(D_logits_fake,tf.zeros_like(D_logits_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_loss = D_real_loss + D_fake_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_loss = loss_func(D_logits_fake,tf.ones_like(D_logits_fake))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dis/dense/kernel:0', 'dis/dense/bias:0', 'dis/dense_1/kernel:0', 'dis/dense_1/bias:0', 'dis/dense_2/kernel:0', 'dis/dense_2/bias:0']\n",
      "['gen/dense/kernel:0', 'gen/dense/bias:0', 'gen/dense_1/kernel:0', 'gen/dense_1/bias:0', 'gen/dense_2/kernel:0', 'gen/dense_2/bias:0']\n"
     ]
    }
   ],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in tvars if 'dis' in var.name]\n",
    "g_vars = [var for var in tvars if 'gen' in var.name]\n",
    "\n",
    "print([v.name for v in d_vars])\n",
    "print([v.name for v in g_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_trainer = tf.train.AdamOptimizer(learning_rate).minimize(D_loss, var_list=d_vars)\n",
    "G_trainer = tf.train.AdamOptimizer(learning_rate).minimize(G_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 500\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver(var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a sample per epoch\n",
    "samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/500_epoch_model.ckpt\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (1, 10) for Tensor 'Placeholder_1:0', which has shape '(?, 100)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-7cebfdd8cd9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0msample_z\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mgen_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0msample_z\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mnew_samples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Misc\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Misc\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1074\u001b[0m                              \u001b[1;34m'which has shape %r'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[1;32m-> 1076\u001b[1;33m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m   1077\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (1, 10) for Tensor 'Placeholder_1:0', which has shape '(?, 100)'"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver(var_list=g_vars)\n",
    "\n",
    "new_samples = []\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    saver.restore(sess,'./models/500_epoch_model.ckpt')\n",
    "    \n",
    "    for x in range(15):\n",
    "        sample_z = np.random.uniform(-1,1,size=(1,100))\n",
    "        gen_sample = sess.run(generator(z,reuse=True),feed_dict={z:sample_z})\n",
    "        \n",
    "        new_samples.append(gen_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    # Recall an epoch is an entire run through the training data\n",
    "    for e in range(epochs):\n",
    "        # // indicates classic division\n",
    "        num_batches = mnist.train.num_examples // batch_size\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            \n",
    "            # Grab batch of images\n",
    "            batch = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            # Get images, reshape and rescale to pass to D\n",
    "            batch_images = batch[0].reshape((batch_size, 784))\n",
    "            batch_images = batch_images*2 - 1\n",
    "            \n",
    "            # Z (random latent noise data for Generator)\n",
    "            # -1 to 1 because of tanh activation\n",
    "            batch_z = np.random.uniform(-1, 1, size=(batch_size, 100))\n",
    "            \n",
    "            # Run optimizers, no need to save outputs, we won't use them\n",
    "            _ = sess.run(D_trainer, feed_dict={real_images: batch_images, z: batch_z})\n",
    "            _ = sess.run(G_trainer, feed_dict={z: batch_z})\n",
    "        \n",
    "            \n",
    "        print(\"Currently on Epoch {} of {} total...\".format(e+1, epochs))\n",
    "        \n",
    "        # Sample from generator as we're training for viewing afterwards\n",
    "        sample_z = np.random.uniform(-1, 1, size=(1, 100))\n",
    "        gen_sample = sess.run(generator(z ,reuse=True),feed_dict={z: sample_z})\n",
    "        \n",
    "        samples.append(gen_sample)\n",
    "        \n",
    "#         saver.save(sess, './models/500_epoch_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/500_epoch_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver(var_list=g_vars)\n",
    "\n",
    "new_samples = []\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    saver.restore(sess,'./models/500_epoch_model.ckpt')\n",
    "    \n",
    "    for x in range(15):\n",
    "        sample_z = np.random.uniform(,1,size=(1,100))\n",
    "        gen_sample = sess.run(generator(z,reuse=True),feed_dict={z:sample_z})\n",
    "        \n",
    "        new_samples.append(gen_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x208c38a438>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(new_samples[7].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
